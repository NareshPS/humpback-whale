{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras support\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.densenet import DenseNet121 as DenseNet\n",
    "from keras.applications.resnet50 import ResNet50 as ResNet\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "#Plotting\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pandas import read_csv\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from common import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = read_csv(constants.PROCESSED_DATASET_MAPPINGS['labels'])\n",
    "n_classes = len(set(label_df[\"Id\"]))\n",
    "\n",
    "print(\"Number of classes: {}\".format(n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape = (224, 224, 3))\n",
    "X = DenseNet(weights = 'imagenet')(inputs)\n",
    "X = Dense(n_classes, activation = 'softmax')(X)\n",
    "\n",
    "model = Model(inputs = [inputs], outputs = [X])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "\n",
    "base_model = ResNet(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(300, activation=\"softmax\"))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape_no_channel = (224, 224)\n",
    "batch_size = 64\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    validation_split = 0.2)\n",
    "\n",
    "train_gen = datagen.flow_from_dataframe(\n",
    "                    label_df,\n",
    "                    constants.PROCESSED_DATASET_MAPPINGS['train'],\n",
    "                    x_col = 'Image',\n",
    "                    y_col = 'Id',\n",
    "                    target_size=input_shape_no_channel,\n",
    "                    batch_size=batch_size,\n",
    "                    class_mode='categorical',\n",
    "                    subset = 'training')\n",
    "\n",
    "val_gen = datagen.flow_from_dataframe(\n",
    "                    label_df,\n",
    "                    constants.PROCESSED_DATASET_MAPPINGS['train'],\n",
    "                    x_col = 'Image',\n",
    "                    y_col = 'Id',\n",
    "                    target_size=input_shape_no_channel,\n",
    "                    batch_size=batch_size,\n",
    "                    class_mode='categorical',\n",
    "                    subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = train_gen.next()\n",
    "n_images = 2 # X.shape[0]\n",
    "\n",
    "\n",
    "output = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = X.shape[0]\n",
    "\n",
    "\"\"\"\n",
    "nn = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(X)\n",
    "nbrs = nn.kneighbors(X[0], n_neighbors=5, return_distance=True)\n",
    "print(nbrs.shape)\n",
    "\"\"\"\n",
    "\n",
    "for img_row in range(n_images):\n",
    "    rows = []\n",
    "    for img_col in range(n_images):\n",
    "        rows.append(np.linalg.norm(output[img_row] - output[img_col]))\n",
    "    \n",
    "    img_id = np.argmax(rows)\n",
    "    print((img_row, img_id), np.amax(rows), (np.nonzero(Y[img_row]), np.nonzero(Y[img_id])))\n",
    "    \n",
    "figure, axes = plt.subplots(2, 2)\n",
    "axes[0, 0].imshow(X[4])\n",
    "axes[0, 1].imshow(X[14])\n",
    "axes[1, 0].imshow(X[41])\n",
    "axes[1, 1].imshow(X[42])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras imports\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Dense, BatchNormalization, Activation, Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "#Feature model\n",
    "from resnet_feature_model import resnet_feature_model as feature_model\n",
    "\n",
    "#Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Load and save objects to disk\n",
    "from pandas import read_csv\n",
    "\n",
    "#Allow reproducible results\n",
    "from numpy.random import seed as np_seed\n",
    "from tensorflow import set_random_seed as tf_seed\n",
    "\n",
    "#Constants\n",
    "from common import constants\n",
    "\n",
    "def siamese_network_model(input_shape, feature_dims):\n",
    "    anchor_input = Input(shape = input_shape, name = 'Anchor')\n",
    "    sample_input = Input(shape = input_shape, name = 'Sample')\n",
    "\n",
    "    anchor_features = feature_model(input_shape, feature_dims)(anchor_input)\n",
    "    sample_features = feature_model(input_shape, feature_dims)(sample_input)\n",
    "\n",
    "    X = Concatenate()([anchor_features, sample_features])\n",
    "    X = Dense(16, activation = 'linear')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Dense(4, activation = 'linear')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Dense(1, activation = 'sigmoid')(X)\n",
    "\n",
    "    siamese_network = Model(inputs = [anchor_input, sample_input], outputs = [X], name = 'Siamese Model')\n",
    "    siamese_network.summary()\n",
    "\n",
    "    return siamese_network\n",
    "\n",
    "def make_datagen(batch_size, validation_split = None):\n",
    "    idg_kwargs = dict(\n",
    "                    rescale = 1./255, shear_range = 0.2,\n",
    "                    rotation_range=10, width_shift_range=0.2,\n",
    "                    height_shift_range=0.2, zoom_range = 0.2, horizontal_flip= True)\n",
    "\n",
    "    datagen = None\n",
    "\n",
    "    if validation_split:\n",
    "        datagen = ImageDataGenerator(validation_split = validation_split, **idg_kwargs)\n",
    "    else:\n",
    "        datagen = ImageDataGenerator(**idg_kwargs)\n",
    "\n",
    "    return datagen\n",
    "\n",
    "def make_generators(datagen, source, train_tuples_df, x_col, y_col, batch_size, validation_split = None):\n",
    "    input_shape_nc = (224, 224)\n",
    "    val_gen = None\n",
    "\n",
    "    flow_kwargs = dict(\n",
    "                    x_col = x_col, y_col = y_col, target_size = input_shape_nc,\n",
    "                    batch_size = batch_size)\n",
    "\n",
    "    if validation_split:\n",
    "        val_gen = datagen.flow_from_dataframe(train_tuples_df, source, subset = 'validation', **flow_kwargs)\n",
    "\n",
    "    train_gen = datagen.flow_from_dataframe(train_tuples_df, source, subset = 'training', **flow_kwargs)\n",
    "\n",
    "    return train_gen, val_gen\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #Fix randomness\n",
    "    seed = 3\n",
    "    np_seed(3)\n",
    "    tf_seed(3)\n",
    "    df_image_col = constants.IMAGE_HEADER_NAME\n",
    "    df_class_col = constants.LABEL_HEADER_NAME\n",
    "    input_shape = constants.INPUT_SHAPE\n",
    "    feature_dims = constants.FEATURE_VECTOR_DIMS\n",
    "    train_set_loc = constants.PROCESSED_DATASET_MAPPINGS['train']\n",
    "    anchor_field = constants.TRAIN_TUPLE_HEADERS[0]\n",
    "    sample_field = constants.TRAIN_TUPLE_HEADERS[1]\n",
    "    similar_field = constants.TRAIN_TUPLE_HEADERS[3]\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    train_tuples_df = read_csv(constants.PROCESSED_DATASET_MAPPINGS['train_tuples'])\n",
    "    datagen = make_datagen(batch_size)\n",
    "    anchor_train_gen, _ = make_generators(datagen, train_set_loc, train_tuples_df, anchor_field, similar_field, batch_size)\n",
    "    sample_train_gen, _ = make_generators(datagen, train_set_loc, train_tuples_df, sample_field, similar_field, batch_size)\n",
    "\n",
    "    batch_anchor = anchor_train_gen.next()\n",
    "    batch_sample = sample_train_gen.next()\n",
    "\n",
    "    print(batch_sample[0].shape)\n",
    "\n",
    "    #model = siamese_network_model(input_shape, feature_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_sample[1].shape)\n",
    "print(batch_anchor[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from common import constants\n",
    "\n",
    "train_tuples_loc = constants.PROCESSED_DATASET_MAPPINGS['train_tuples']\n",
    "train_tuples_df = read_csv(train_tuples_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('inceptionv3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 False\n",
      "conv2d_1 False\n",
      "batch_normalization_1 False\n",
      "activation_1 False\n",
      "conv2d_2 False\n",
      "batch_normalization_2 False\n",
      "activation_2 False\n",
      "conv2d_3 False\n",
      "batch_normalization_3 False\n",
      "activation_3 False\n",
      "max_pooling2d_1 False\n",
      "conv2d_4 False\n",
      "batch_normalization_4 False\n",
      "activation_4 False\n",
      "conv2d_5 False\n",
      "batch_normalization_5 False\n",
      "activation_5 False\n",
      "max_pooling2d_2 False\n",
      "conv2d_9 False\n",
      "batch_normalization_9 False\n",
      "activation_9 False\n",
      "conv2d_7 False\n",
      "conv2d_10 False\n",
      "batch_normalization_7 False\n",
      "batch_normalization_10 False\n",
      "activation_7 False\n",
      "activation_10 False\n",
      "average_pooling2d_1 False\n",
      "conv2d_6 False\n",
      "conv2d_8 False\n",
      "conv2d_11 False\n",
      "conv2d_12 False\n",
      "batch_normalization_6 False\n",
      "batch_normalization_8 False\n",
      "batch_normalization_11 False\n",
      "batch_normalization_12 False\n",
      "activation_6 False\n",
      "activation_8 False\n",
      "activation_11 False\n",
      "activation_12 False\n",
      "mixed0 False\n",
      "conv2d_16 False\n",
      "batch_normalization_16 False\n",
      "activation_16 False\n",
      "conv2d_14 False\n",
      "conv2d_17 False\n",
      "batch_normalization_14 False\n",
      "batch_normalization_17 False\n",
      "activation_14 False\n",
      "activation_17 False\n",
      "average_pooling2d_2 False\n",
      "conv2d_13 False\n",
      "conv2d_15 False\n",
      "conv2d_18 False\n",
      "conv2d_19 False\n",
      "batch_normalization_13 False\n",
      "batch_normalization_15 False\n",
      "batch_normalization_18 False\n",
      "batch_normalization_19 False\n",
      "activation_13 False\n",
      "activation_15 False\n",
      "activation_18 False\n",
      "activation_19 False\n",
      "mixed1 False\n",
      "conv2d_23 False\n",
      "batch_normalization_23 False\n",
      "activation_23 False\n",
      "conv2d_21 False\n",
      "conv2d_24 False\n",
      "batch_normalization_21 False\n",
      "batch_normalization_24 False\n",
      "activation_21 False\n",
      "activation_24 False\n",
      "average_pooling2d_3 False\n",
      "conv2d_20 False\n",
      "conv2d_22 False\n",
      "conv2d_25 False\n",
      "conv2d_26 False\n",
      "batch_normalization_20 False\n",
      "batch_normalization_22 False\n",
      "batch_normalization_25 False\n",
      "batch_normalization_26 False\n",
      "activation_20 False\n",
      "activation_22 False\n",
      "activation_25 False\n",
      "activation_26 False\n",
      "mixed2 False\n",
      "conv2d_28 False\n",
      "batch_normalization_28 False\n",
      "activation_28 False\n",
      "conv2d_29 False\n",
      "batch_normalization_29 False\n",
      "activation_29 False\n",
      "conv2d_27 False\n",
      "conv2d_30 False\n",
      "batch_normalization_27 False\n",
      "batch_normalization_30 False\n",
      "activation_27 False\n",
      "activation_30 False\n",
      "max_pooling2d_3 False\n",
      "mixed3 False\n",
      "conv2d_35 False\n",
      "batch_normalization_35 False\n",
      "activation_35 False\n",
      "conv2d_36 False\n",
      "batch_normalization_36 False\n",
      "activation_36 False\n",
      "conv2d_32 False\n",
      "conv2d_37 False\n",
      "batch_normalization_32 False\n",
      "batch_normalization_37 False\n",
      "activation_32 False\n",
      "activation_37 False\n",
      "conv2d_33 False\n",
      "conv2d_38 False\n",
      "batch_normalization_33 False\n",
      "batch_normalization_38 False\n",
      "activation_33 False\n",
      "activation_38 False\n",
      "average_pooling2d_4 False\n",
      "conv2d_31 False\n",
      "conv2d_34 False\n",
      "conv2d_39 False\n",
      "conv2d_40 False\n",
      "batch_normalization_31 False\n",
      "batch_normalization_34 False\n",
      "batch_normalization_39 False\n",
      "batch_normalization_40 False\n",
      "activation_31 False\n",
      "activation_34 False\n",
      "activation_39 False\n",
      "activation_40 False\n",
      "mixed4 False\n",
      "conv2d_45 False\n",
      "batch_normalization_45 False\n",
      "activation_45 False\n",
      "conv2d_46 False\n",
      "batch_normalization_46 False\n",
      "activation_46 False\n",
      "conv2d_42 False\n",
      "conv2d_47 False\n",
      "batch_normalization_42 False\n",
      "batch_normalization_47 False\n",
      "activation_42 False\n",
      "activation_47 False\n",
      "conv2d_43 False\n",
      "conv2d_48 False\n",
      "batch_normalization_43 False\n",
      "batch_normalization_48 False\n",
      "activation_43 False\n",
      "activation_48 False\n",
      "average_pooling2d_5 False\n",
      "conv2d_41 False\n",
      "conv2d_44 False\n",
      "conv2d_49 False\n",
      "conv2d_50 False\n",
      "batch_normalization_41 False\n",
      "batch_normalization_44 False\n",
      "batch_normalization_49 False\n",
      "batch_normalization_50 False\n",
      "activation_41 False\n",
      "activation_44 False\n",
      "activation_49 False\n",
      "activation_50 False\n",
      "mixed5 False\n",
      "conv2d_55 False\n",
      "batch_normalization_55 False\n",
      "activation_55 False\n",
      "conv2d_56 False\n",
      "batch_normalization_56 False\n",
      "activation_56 False\n",
      "conv2d_52 False\n",
      "conv2d_57 False\n",
      "batch_normalization_52 False\n",
      "batch_normalization_57 False\n",
      "activation_52 False\n",
      "activation_57 False\n",
      "conv2d_53 False\n",
      "conv2d_58 False\n",
      "batch_normalization_53 False\n",
      "batch_normalization_58 False\n",
      "activation_53 False\n",
      "activation_58 False\n",
      "average_pooling2d_6 False\n",
      "conv2d_51 False\n",
      "conv2d_54 False\n",
      "conv2d_59 False\n",
      "conv2d_60 False\n",
      "batch_normalization_51 False\n",
      "batch_normalization_54 False\n",
      "batch_normalization_59 False\n",
      "batch_normalization_60 False\n",
      "activation_51 False\n",
      "activation_54 False\n",
      "activation_59 False\n",
      "activation_60 False\n",
      "mixed6 False\n",
      "conv2d_65 False\n",
      "batch_normalization_65 False\n",
      "activation_65 False\n",
      "conv2d_66 False\n",
      "batch_normalization_66 False\n",
      "activation_66 False\n",
      "conv2d_62 False\n",
      "conv2d_67 False\n",
      "batch_normalization_62 False\n",
      "batch_normalization_67 False\n",
      "activation_62 False\n",
      "activation_67 False\n",
      "conv2d_63 False\n",
      "conv2d_68 False\n",
      "batch_normalization_63 False\n",
      "batch_normalization_68 False\n",
      "activation_63 False\n",
      "activation_68 False\n",
      "average_pooling2d_7 False\n",
      "conv2d_61 False\n",
      "conv2d_64 False\n",
      "conv2d_69 False\n",
      "conv2d_70 False\n",
      "batch_normalization_61 False\n",
      "batch_normalization_64 False\n",
      "batch_normalization_69 False\n",
      "batch_normalization_70 False\n",
      "activation_61 False\n",
      "activation_64 False\n",
      "activation_69 False\n",
      "activation_70 False\n",
      "mixed7 False\n",
      "conv2d_73 False\n",
      "batch_normalization_73 False\n",
      "activation_73 False\n",
      "conv2d_74 False\n",
      "batch_normalization_74 False\n",
      "activation_74 False\n",
      "conv2d_71 False\n",
      "conv2d_75 False\n",
      "batch_normalization_71 False\n",
      "batch_normalization_75 False\n",
      "activation_71 False\n",
      "activation_75 False\n",
      "conv2d_72 False\n",
      "conv2d_76 False\n",
      "batch_normalization_72 False\n",
      "batch_normalization_76 False\n",
      "activation_72 False\n",
      "activation_76 False\n",
      "max_pooling2d_4 False\n",
      "mixed8 False\n",
      "conv2d_81 False\n",
      "batch_normalization_81 False\n",
      "activation_81 False\n",
      "conv2d_78 False\n",
      "conv2d_82 False\n",
      "batch_normalization_78 False\n",
      "batch_normalization_82 False\n",
      "activation_78 False\n",
      "activation_82 False\n",
      "conv2d_79 False\n",
      "conv2d_80 False\n",
      "conv2d_83 False\n",
      "conv2d_84 False\n",
      "average_pooling2d_8 False\n",
      "conv2d_77 False\n",
      "batch_normalization_79 False\n",
      "batch_normalization_80 False\n",
      "batch_normalization_83 False\n",
      "batch_normalization_84 False\n",
      "conv2d_85 False\n",
      "batch_normalization_77 False\n",
      "activation_79 False\n",
      "activation_80 False\n",
      "activation_83 False\n",
      "activation_84 False\n",
      "batch_normalization_85 False\n",
      "activation_77 False\n",
      "mixed9_0 False\n",
      "concatenate_1 False\n",
      "activation_85 False\n",
      "mixed9 False\n",
      "conv2d_90 False\n",
      "batch_normalization_90 False\n",
      "activation_90 False\n",
      "conv2d_87 False\n",
      "conv2d_91 False\n",
      "batch_normalization_87 False\n",
      "batch_normalization_91 False\n",
      "activation_87 False\n",
      "activation_91 False\n",
      "conv2d_88 False\n",
      "conv2d_89 False\n",
      "conv2d_92 False\n",
      "conv2d_93 False\n",
      "average_pooling2d_9 False\n",
      "conv2d_86 False\n",
      "batch_normalization_88 False\n",
      "batch_normalization_89 False\n",
      "batch_normalization_92 False\n",
      "batch_normalization_93 False\n",
      "conv2d_94 False\n",
      "batch_normalization_86 False\n",
      "activation_88 False\n",
      "activation_89 False\n",
      "activation_92 False\n",
      "activation_93 False\n",
      "batch_normalization_94 False\n",
      "activation_86 False\n",
      "mixed9_1 False\n",
      "concatenate_2 False\n",
      "activation_94 False\n",
      "mixed10 False\n",
      "global_average_pooling2d_1 True\n",
      "dense_1 True\n",
      "dense_2 True\n",
      "input_2 False\n",
      "conv2d_95 False\n",
      "batch_normalization_95 False\n",
      "activation_95 False\n",
      "conv2d_96 False\n",
      "batch_normalization_96 False\n",
      "activation_96 False\n",
      "conv2d_97 False\n",
      "batch_normalization_97 False\n",
      "activation_97 False\n",
      "max_pooling2d_5 False\n",
      "conv2d_98 False\n",
      "batch_normalization_98 False\n",
      "activation_98 False\n",
      "conv2d_99 False\n",
      "batch_normalization_99 False\n",
      "activation_99 False\n",
      "max_pooling2d_6 False\n",
      "conv2d_103 False\n",
      "batch_normalization_103 False\n",
      "activation_103 False\n",
      "conv2d_101 False\n",
      "conv2d_104 False\n",
      "batch_normalization_101 False\n",
      "batch_normalization_104 False\n",
      "activation_101 False\n",
      "activation_104 False\n",
      "average_pooling2d_10 False\n",
      "conv2d_100 False\n",
      "conv2d_102 False\n",
      "conv2d_105 False\n",
      "conv2d_106 False\n",
      "batch_normalization_100 False\n",
      "batch_normalization_102 False\n",
      "batch_normalization_105 False\n",
      "batch_normalization_106 False\n",
      "activation_100 False\n",
      "activation_102 False\n",
      "activation_105 False\n",
      "activation_106 False\n",
      "mixed0 False\n",
      "conv2d_110 False\n",
      "batch_normalization_110 False\n",
      "activation_110 False\n",
      "conv2d_108 False\n",
      "conv2d_111 False\n",
      "batch_normalization_108 False\n",
      "batch_normalization_111 False\n",
      "activation_108 False\n",
      "activation_111 False\n",
      "average_pooling2d_11 False\n",
      "conv2d_107 False\n",
      "conv2d_109 False\n",
      "conv2d_112 False\n",
      "conv2d_113 False\n",
      "batch_normalization_107 False\n",
      "batch_normalization_109 False\n",
      "batch_normalization_112 False\n",
      "batch_normalization_113 False\n",
      "activation_107 False\n",
      "activation_109 False\n",
      "activation_112 False\n",
      "activation_113 False\n",
      "mixed1 False\n",
      "conv2d_117 False\n",
      "batch_normalization_117 False\n",
      "activation_117 False\n",
      "conv2d_115 False\n",
      "conv2d_118 False\n",
      "batch_normalization_115 False\n",
      "batch_normalization_118 False\n",
      "activation_115 False\n",
      "activation_118 False\n",
      "average_pooling2d_12 False\n",
      "conv2d_114 False\n",
      "conv2d_116 False\n",
      "conv2d_119 False\n",
      "conv2d_120 False\n",
      "batch_normalization_114 False\n",
      "batch_normalization_116 False\n",
      "batch_normalization_119 False\n",
      "batch_normalization_120 False\n",
      "activation_114 False\n",
      "activation_116 False\n",
      "activation_119 False\n",
      "activation_120 False\n",
      "mixed2 False\n",
      "conv2d_122 False\n",
      "batch_normalization_122 False\n",
      "activation_122 False\n",
      "conv2d_123 False\n",
      "batch_normalization_123 False\n",
      "activation_123 False\n",
      "conv2d_121 False\n",
      "conv2d_124 False\n",
      "batch_normalization_121 False\n",
      "batch_normalization_124 False\n",
      "activation_121 False\n",
      "activation_124 False\n",
      "max_pooling2d_7 False\n",
      "mixed3 False\n",
      "conv2d_129 False\n",
      "batch_normalization_129 False\n",
      "activation_129 False\n",
      "conv2d_130 False\n",
      "batch_normalization_130 False\n",
      "activation_130 False\n",
      "conv2d_126 False\n",
      "conv2d_131 False\n",
      "batch_normalization_126 False\n",
      "batch_normalization_131 False\n",
      "activation_126 False\n",
      "activation_131 False\n",
      "conv2d_127 False\n",
      "conv2d_132 False\n",
      "batch_normalization_127 False\n",
      "batch_normalization_132 False\n",
      "activation_127 False\n",
      "activation_132 False\n",
      "average_pooling2d_13 False\n",
      "conv2d_125 False\n",
      "conv2d_128 False\n",
      "conv2d_133 False\n",
      "conv2d_134 False\n",
      "batch_normalization_125 False\n",
      "batch_normalization_128 False\n",
      "batch_normalization_133 False\n",
      "batch_normalization_134 False\n",
      "activation_125 False\n",
      "activation_128 False\n",
      "activation_133 False\n",
      "activation_134 False\n",
      "mixed4 False\n",
      "conv2d_139 False\n",
      "batch_normalization_139 False\n",
      "activation_139 False\n",
      "conv2d_140 False\n",
      "batch_normalization_140 False\n",
      "activation_140 False\n",
      "conv2d_136 False\n",
      "conv2d_141 False\n",
      "batch_normalization_136 False\n",
      "batch_normalization_141 False\n",
      "activation_136 False\n",
      "activation_141 False\n",
      "conv2d_137 False\n",
      "conv2d_142 False\n",
      "batch_normalization_137 False\n",
      "batch_normalization_142 False\n",
      "activation_137 False\n",
      "activation_142 False\n",
      "average_pooling2d_14 False\n",
      "conv2d_135 False\n",
      "conv2d_138 False\n",
      "conv2d_143 False\n",
      "conv2d_144 False\n",
      "batch_normalization_135 False\n",
      "batch_normalization_138 False\n",
      "batch_normalization_143 False\n",
      "batch_normalization_144 False\n",
      "activation_135 False\n",
      "activation_138 False\n",
      "activation_143 False\n",
      "activation_144 False\n",
      "mixed5 False\n",
      "conv2d_149 False\n",
      "batch_normalization_149 False\n",
      "activation_149 False\n",
      "conv2d_150 False\n",
      "batch_normalization_150 False\n",
      "activation_150 False\n",
      "conv2d_146 False\n",
      "conv2d_151 False\n",
      "batch_normalization_146 False\n",
      "batch_normalization_151 False\n",
      "activation_146 False\n",
      "activation_151 False\n",
      "conv2d_147 False\n",
      "conv2d_152 False\n",
      "batch_normalization_147 False\n",
      "batch_normalization_152 False\n",
      "activation_147 False\n",
      "activation_152 False\n",
      "average_pooling2d_15 False\n",
      "conv2d_145 False\n",
      "conv2d_148 False\n",
      "conv2d_153 False\n",
      "conv2d_154 False\n",
      "batch_normalization_145 False\n",
      "batch_normalization_148 False\n",
      "batch_normalization_153 False\n",
      "batch_normalization_154 False\n",
      "activation_145 False\n",
      "activation_148 False\n",
      "activation_153 False\n",
      "activation_154 False\n",
      "mixed6 False\n",
      "conv2d_159 False\n",
      "batch_normalization_159 False\n",
      "activation_159 False\n",
      "conv2d_160 False\n",
      "batch_normalization_160 False\n",
      "activation_160 False\n",
      "conv2d_156 False\n",
      "conv2d_161 False\n",
      "batch_normalization_156 False\n",
      "batch_normalization_161 False\n",
      "activation_156 False\n",
      "activation_161 False\n",
      "conv2d_157 False\n",
      "conv2d_162 False\n",
      "batch_normalization_157 False\n",
      "batch_normalization_162 False\n",
      "activation_157 False\n",
      "activation_162 False\n",
      "average_pooling2d_16 False\n",
      "conv2d_155 False\n",
      "conv2d_158 False\n",
      "conv2d_163 False\n",
      "conv2d_164 False\n",
      "batch_normalization_155 False\n",
      "batch_normalization_158 False\n",
      "batch_normalization_163 False\n",
      "batch_normalization_164 False\n",
      "activation_155 False\n",
      "activation_158 False\n",
      "activation_163 False\n",
      "activation_164 False\n",
      "mixed7 False\n",
      "conv2d_167 False\n",
      "batch_normalization_167 False\n",
      "activation_167 False\n",
      "conv2d_168 False\n",
      "batch_normalization_168 False\n",
      "activation_168 False\n",
      "conv2d_165 False\n",
      "conv2d_169 False\n",
      "batch_normalization_165 False\n",
      "batch_normalization_169 False\n",
      "activation_165 False\n",
      "activation_169 False\n",
      "conv2d_166 False\n",
      "conv2d_170 False\n",
      "batch_normalization_166 False\n",
      "batch_normalization_170 False\n",
      "activation_166 False\n",
      "activation_170 False\n",
      "max_pooling2d_8 False\n",
      "mixed8 False\n",
      "conv2d_175 False\n",
      "batch_normalization_175 False\n",
      "activation_175 False\n",
      "conv2d_172 False\n",
      "conv2d_176 False\n",
      "batch_normalization_172 False\n",
      "batch_normalization_176 False\n",
      "activation_172 False\n",
      "activation_176 False\n",
      "conv2d_173 False\n",
      "conv2d_174 False\n",
      "conv2d_177 False\n",
      "conv2d_178 False\n",
      "average_pooling2d_17 False\n",
      "conv2d_171 False\n",
      "batch_normalization_173 False\n",
      "batch_normalization_174 False\n",
      "batch_normalization_177 False\n",
      "batch_normalization_178 False\n",
      "conv2d_179 False\n",
      "batch_normalization_171 False\n",
      "activation_173 False\n",
      "activation_174 False\n",
      "activation_177 False\n",
      "activation_178 False\n",
      "batch_normalization_179 False\n",
      "activation_171 False\n",
      "mixed9_0 False\n",
      "concatenate_3 False\n",
      "activation_179 False\n",
      "mixed9 False\n",
      "conv2d_184 False\n",
      "batch_normalization_184 False\n",
      "activation_184 False\n",
      "conv2d_181 False\n",
      "conv2d_185 False\n",
      "batch_normalization_181 False\n",
      "batch_normalization_185 False\n",
      "activation_181 False\n",
      "activation_185 False\n",
      "conv2d_182 False\n",
      "conv2d_183 False\n",
      "conv2d_186 False\n",
      "conv2d_187 False\n",
      "average_pooling2d_18 False\n",
      "conv2d_180 False\n",
      "batch_normalization_182 False\n",
      "batch_normalization_183 False\n",
      "batch_normalization_186 False\n",
      "batch_normalization_187 False\n",
      "conv2d_188 False\n",
      "batch_normalization_180 False\n",
      "activation_182 False\n",
      "activation_183 False\n",
      "activation_186 False\n",
      "activation_187 False\n",
      "batch_normalization_188 False\n",
      "activation_180 False\n",
      "mixed9_1 False\n",
      "concatenate_4 False\n",
      "activation_188 False\n",
      "mixed10 False\n",
      "global_average_pooling2d_2 True\n",
      "dense_3 True\n",
      "dense_4 True\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, keras.engine.training.Model):\n",
    "        for sub_layer in layer.layers:\n",
    "            print(sub_layer.name, sub_layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
