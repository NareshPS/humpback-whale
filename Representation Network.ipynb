{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras support\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.densenet import DenseNet121 as DenseNet\n",
    "from keras.applications.resnet50 import ResNet50 as ResNet\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "#Plotting\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pandas import read_csv\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from common import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = read_csv(constants.PROCESSED_DATASET_MAPPINGS['labels'])\n",
    "n_classes = len(set(label_df[\"Id\"]))\n",
    "\n",
    "print(\"Number of classes: {}\".format(n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape = (224, 224, 3))\n",
    "X = DenseNet(weights = 'imagenet')(inputs)\n",
    "X = Dense(n_classes, activation = 'softmax')(X)\n",
    "\n",
    "model = Model(inputs = [inputs], outputs = [X])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "\n",
    "base_model = ResNet(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(300, activation=\"softmax\"))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape_no_channel = (224, 224)\n",
    "batch_size = 64\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    validation_split = 0.2)\n",
    "\n",
    "train_gen = datagen.flow_from_dataframe(\n",
    "                    label_df,\n",
    "                    constants.PROCESSED_DATASET_MAPPINGS['train'],\n",
    "                    x_col = 'Image',\n",
    "                    y_col = 'Id',\n",
    "                    target_size=input_shape_no_channel,\n",
    "                    batch_size=batch_size,\n",
    "                    class_mode='categorical',\n",
    "                    subset = 'training')\n",
    "\n",
    "val_gen = datagen.flow_from_dataframe(\n",
    "                    label_df,\n",
    "                    constants.PROCESSED_DATASET_MAPPINGS['train'],\n",
    "                    x_col = 'Image',\n",
    "                    y_col = 'Id',\n",
    "                    target_size=input_shape_no_channel,\n",
    "                    batch_size=batch_size,\n",
    "                    class_mode='categorical',\n",
    "                    subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = train_gen.next()\n",
    "n_images = 2 # X.shape[0]\n",
    "\n",
    "\n",
    "output = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = X.shape[0]\n",
    "\n",
    "\"\"\"\n",
    "nn = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(X)\n",
    "nbrs = nn.kneighbors(X[0], n_neighbors=5, return_distance=True)\n",
    "print(nbrs.shape)\n",
    "\"\"\"\n",
    "\n",
    "for img_row in range(n_images):\n",
    "    rows = []\n",
    "    for img_col in range(n_images):\n",
    "        rows.append(np.linalg.norm(output[img_row] - output[img_col]))\n",
    "    \n",
    "    img_id = np.argmax(rows)\n",
    "    print((img_row, img_id), np.amax(rows), (np.nonzero(Y[img_row]), np.nonzero(Y[img_id])))\n",
    "    \n",
    "figure, axes = plt.subplots(2, 2)\n",
    "axes[0, 0].imshow(X[4])\n",
    "axes[0, 1].imshow(X[14])\n",
    "axes[1, 0].imshow(X[41])\n",
    "axes[1, 1].imshow(X[42])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\nares\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image.py:2059: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.df[x_col] = self.df[x_col].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1024 images belonging to 1 classes.\n",
      "Found 1024 images belonging to 2 classes.\n",
      "(32, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "#Keras imports\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Dense, BatchNormalization, Activation, Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "#Feature model\n",
    "from resnet_feature_model import resnet_feature_model as feature_model\n",
    "\n",
    "#Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Load and save objects to disk\n",
    "from pandas import read_csv\n",
    "\n",
    "#Allow reproducible results\n",
    "from numpy.random import seed as np_seed\n",
    "from tensorflow import set_random_seed as tf_seed\n",
    "\n",
    "#Constants\n",
    "from common import constants\n",
    "\n",
    "def siamese_network_model(input_shape, feature_dims):\n",
    "    anchor_input = Input(shape = input_shape, name = 'Anchor')\n",
    "    sample_input = Input(shape = input_shape, name = 'Sample')\n",
    "\n",
    "    anchor_features = feature_model(input_shape, feature_dims)(anchor_input)\n",
    "    sample_features = feature_model(input_shape, feature_dims)(sample_input)\n",
    "\n",
    "    X = Concatenate()([anchor_features, sample_features])\n",
    "    X = Dense(16, activation = 'linear')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Dense(4, activation = 'linear')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = Dense(1, activation = 'sigmoid')(X)\n",
    "\n",
    "    siamese_network = Model(inputs = [anchor_input, sample_input], outputs = [X], name = 'Siamese Model')\n",
    "    siamese_network.summary()\n",
    "\n",
    "    return siamese_network\n",
    "\n",
    "def make_datagen(batch_size, validation_split = None):\n",
    "    idg_kwargs = dict(\n",
    "                    rescale = 1./255, shear_range = 0.2,\n",
    "                    rotation_range=10, width_shift_range=0.2,\n",
    "                    height_shift_range=0.2, zoom_range = 0.2, horizontal_flip= True)\n",
    "\n",
    "    datagen = None\n",
    "\n",
    "    if validation_split:\n",
    "        datagen = ImageDataGenerator(validation_split = validation_split, **idg_kwargs)\n",
    "    else:\n",
    "        datagen = ImageDataGenerator(**idg_kwargs)\n",
    "\n",
    "    return datagen\n",
    "\n",
    "def make_generators(datagen, source, train_tuples_df, x_col, y_col, batch_size, validation_split = None):\n",
    "    input_shape_nc = (224, 224)\n",
    "    val_gen = None\n",
    "\n",
    "    flow_kwargs = dict(\n",
    "                    x_col = x_col, y_col = y_col, target_size = input_shape_nc,\n",
    "                    batch_size = batch_size)\n",
    "\n",
    "    if validation_split:\n",
    "        val_gen = datagen.flow_from_dataframe(train_tuples_df, source, subset = 'validation', **flow_kwargs)\n",
    "\n",
    "    train_gen = datagen.flow_from_dataframe(train_tuples_df, source, subset = 'training', **flow_kwargs)\n",
    "\n",
    "    return train_gen, val_gen\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #Fix randomness\n",
    "    seed = 3\n",
    "    np_seed(3)\n",
    "    tf_seed(3)\n",
    "    df_image_col = constants.IMAGE_HEADER_NAME\n",
    "    df_class_col = constants.LABEL_HEADER_NAME\n",
    "    input_shape = constants.INPUT_SHAPE\n",
    "    feature_dims = constants.FEATURE_VECTOR_DIMS\n",
    "    train_set_loc = constants.PROCESSED_DATASET_MAPPINGS['train']\n",
    "    anchor_field = constants.TRAIN_TUPLE_HEADERS[0]\n",
    "    sample_field = constants.TRAIN_TUPLE_HEADERS[1]\n",
    "    similar_field = constants.TRAIN_TUPLE_HEADERS[3]\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    train_tuples_df = read_csv(constants.PROCESSED_DATASET_MAPPINGS['train_tuples'])\n",
    "    datagen = make_datagen(batch_size)\n",
    "    anchor_train_gen, _ = make_generators(datagen, train_set_loc, train_tuples_df, anchor_field, similar_field, batch_size)\n",
    "    sample_train_gen, _ = make_generators(datagen, train_set_loc, train_tuples_df, sample_field, similar_field, batch_size)\n",
    "\n",
    "    batch_anchor = anchor_train_gen.next()\n",
    "    batch_sample = sample_train_gen.next()\n",
    "\n",
    "    print(batch_sample[0].shape)\n",
    "\n",
    "    #model = siamese_network_model(input_shape, feature_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 2)\n",
      "(32, 1)\n"
     ]
    }
   ],
   "source": [
    "print(batch_sample[1].shape)\n",
    "print(batch_anchor[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from common import constants\n",
    "\n",
    "train_tuples_loc = constants.PROCESSED_DATASET_MAPPINGS['train_tuples']\n",
    "train_tuples_df = read_csv(train_tuples_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
