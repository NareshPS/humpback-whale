{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using learning rate: 0.001\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 398, 32)           67232     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 396, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 198, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 198, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 196, 64)           6208      \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 194, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 97, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 97, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6208)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1589504   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5005)              1286285   \n",
      "=================================================================\n",
      "Total params: 2,964,685\n",
      "Trainable params: 2,964,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training set: 16 validation set: 4\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.5656 - acc: 0.0000e+00 - val_loss: 8.5440 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 8.5776 - acc: 0.0000e+00 - val_loss: 8.5322 - val_acc: 0.0000e+00\n",
      "Saving model: model_1.h5 and history: model_1.hist\n"
     ]
    }
   ],
   "source": [
    "#Basic imports\n",
    "from sys import argv, stdout\n",
    "\n",
    "#To save training data\n",
    "from pickle import dump as pickle_dump\n",
    "\n",
    "#Local imports\n",
    "from common import constants\n",
    "from models import cnn_gray_model_1\n",
    "from model_utils import get_input_labels, get_label_ids, model_fit\n",
    "from utils import list_files\n",
    "\n",
    "batch_size = 16\n",
    "n_images = 20\n",
    "n_epochs = 2\n",
    "o_model = \"model_1\"\n",
    "l_rate = 0.001\n",
    "\n",
    "dataset = \"train\"\n",
    "validation_split = 0.2\n",
    "input_shape = constants.IMG_SHAPE\n",
    "source_loc = constants.PROCESSED_DATASET_MAPPINGS[dataset]\n",
    "\n",
    "input_labels = get_input_labels()\n",
    "label_ids = get_label_ids()\n",
    "num_classes = len(label_ids)\n",
    "input_set = list_files(source_loc, n_images)\n",
    "\n",
    "#Output model file\n",
    "model_file = \"{o_model}.h5\".format(o_model = o_model)\n",
    "\n",
    "#Initialize the model\n",
    "model = cnn_gray_model_1(input_shape, num_classes, l_rate)\n",
    "model.summary()\n",
    "\n",
    "#Train the model\n",
    "history = model_fit(model, source_loc, input_set, input_labels, label_ids, batch_size, n_epochs, validation_split)\n",
    "\n",
    "#Output model file\n",
    "model_file = \"{o_model}.h5\".format(o_model = o_model)\n",
    "history_file = \"{o_model}.hist\".format(o_model = o_model)\n",
    "\n",
    "#Save model data\n",
    "print(\"Saving model: {model_file} and history: {history_file}\".format(model_file = model_file, history_file = history_file))\n",
    "model.save(model_file, overwrite=True)\n",
    "\n",
    "with open(history_file, 'wb') as handle:\n",
    "    pickle_dump(history.history, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_img(source_path, label_dict, num_files = 10):\n",
    "    files = list(label_dict.keys())[:num_files]\n",
    "\n",
    "    x = load_dataset(source_path, files)\n",
    "    x = to_grayscale(x)\n",
    "\n",
    "    y = [CLASS_NAME_MAP[LABEL_DICT[image]] for image in files]\n",
    "    y = to_categorical(y, num_classes = NUM_CLASSES)\n",
    "\n",
    "    #Print sample\n",
    "    plt.figure()\n",
    "\n",
    "    print(x[3])\n",
    "    plt.imshow(x[0], cmap='gray')\n",
    "    #plt.imshow(cvtColor((x[4]).astype('uint8'), COLOR_BGR2RGB)) #SAMPLE_IMG_ID\n",
    "\n",
    "    print(y[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(LABEL_DICT.keys())[:10]\n",
    "\n",
    "x = load_dataset(TRAIN_SET_LOC, files)\n",
    "x = to_grayscale(x)\n",
    "\n",
    "y = [CLASS_NAME_MAP[LABEL_DICT[image]] for image in files]\n",
    "y = to_categorical(y, num_classes = NUM_CLASSES)\n",
    "\n",
    "#Print sample\n",
    "plt.figure()\n",
    "\n",
    "print(x[3])\n",
    "plt.imshow(x[0], cmap='gray')\n",
    "#plt.imshow(cvtColor((x[4]).astype('uint8'), COLOR_BGR2RGB)) #SAMPLE_IMG_ID\n",
    "\n",
    "print(y[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the model ###\n",
    "model = Sequential()\n",
    "\n",
    "input_shape = IMG_SIZE\n",
    "\n",
    "model.add(MaxPool2D((5, 5), (2, 2), 'valid', input_shape=input_shape))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPool2D((5, 5), (2, 2), 'valid'))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool2D((5, 5), (2, 2), 'valid'))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool2D((5, 5), (2, 2), 'valid'))\n",
    "\n",
    "model.add(Conv2D(8, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool2D((5, 5), (2, 2), 'valid'))\n",
    "\n",
    "model.add(Conv2D(4, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool2D((5, 5), (2, 2), 'valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(NUM_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Print model summary\n",
    "print(model.summary())\n",
    "\n",
    "#Train the model\n",
    "files = list(LABEL_DICT.keys())[:5096]\n",
    "batch_size = 16\n",
    "model.fit_generator(\n",
    "    load_model_data(TRAIN_SET_LOC, files, 16, CLASS_NAME_MAP, LABEL_DICT, NUM_CLASSES),\n",
    "    epochs = 20, \n",
    "    steps_per_epoch = len(files)/batch_size + 1, \n",
    "    use_multiprocessing = True)\n",
    "\"\"\"\n",
    "for files in batch(list(LABEL_DICT.keys()), 256):\n",
    "    x, y = load_image_set(TRAIN_SET_LOC, files, CLASS_NAME_MAP, LABEL_DICT, NUM_CLASSES)\n",
    "    model.fit(x, y, batch_size = 16, validation_split = 0.2, epochs=3)\n",
    "\"\"\"\n",
    "\n",
    "#VG(model_to_dot(model).create(prog='dot', format='s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scratch\n",
    "#img = imread(locate_train_img(\"0000e88ab.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_TRAIN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
