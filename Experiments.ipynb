{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_29 (Conv1D)           (None, 398, 32)           67232     \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 396, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 198, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 198, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 196, 64)           6208      \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 194, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 97, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 97, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 6208)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               1589504   \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 5005)              1286285   \n",
      "=================================================================\n",
      "Total params: 2,964,685\n",
      "Trainable params: 2,964,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "16\n",
      "4\n",
      "Epoch 1/1\n",
      "0\n",
      "0\n",
      "1/1 [==============>...............] - ETA: 2s - loss: 8.5535 - acc: 0.0000e+00"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-cb0e95b64b3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mload_training_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_loc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     validation_steps=(len(validation_set) + batch_size - 1)/batch_size)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m                 \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Basic imports\n",
    "from sys import argv, stdout\n",
    "\n",
    "#Local imports\n",
    "from common import constants\n",
    "from models import model_1\n",
    "from model_utils import get_image_labels, get_label_ids, load_training_batch\n",
    "from utils import list_files\n",
    "\n",
    "batch_size = 16\n",
    "n_images = 20\n",
    "\n",
    "dataset = \"train\"\n",
    "validation_split = 0.2\n",
    "input_shape = constants.IMG_SHAPE\n",
    "source_loc = constants.PROCESSED_DATASET_MAPPINGS[dataset]\n",
    "\n",
    "image_labels = get_image_labels()\n",
    "label_ids = get_label_ids()\n",
    "num_classes = len(label_ids)\n",
    "img_files = list_files(source_loc, n_images)\n",
    "n_images = len(img_files)\n",
    "\n",
    "#Training and validation sets\n",
    "split_marker = int(n_images*(1 - validation_split))\n",
    "train_set = img_files[:split_marker]\n",
    "validation_set = img_files[split_marker:]\n",
    "\n",
    "#Initialize the model\n",
    "model = model_1(input_shape, num_classes)\n",
    "model.summary()\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(validation_set))\n",
    "\n",
    "#Train the model\n",
    "model.fit_generator(\n",
    "    load_training_batch(source_loc, train_set, batch_size, image_labels, label_ids),\n",
    "    steps_per_epoch = (len(train_set) + batch_size - 1)/batch_size,\n",
    "    epochs = 1,\n",
    "    validation_data=load_training_batch(source_loc, validation_set, batch_size, image_labels, label_ids),\n",
    "    validation_steps=(len(validation_set) + batch_size - 1)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_data(source_path, files, batch_size, class_name_map, label_dict, num_classes):\n",
    "    #Image batch placeholder\n",
    "    x = None\n",
    "    \n",
    "    #Labels placeholder\n",
    "    y = None\n",
    "\n",
    "   # with tqdm(total = len(files), file=stdout) as progress_bar:\n",
    "    #    loaded = 0\n",
    "    while True:\n",
    "        shuffle(files)\n",
    "        for batch_files in batch(files, batch_size):\n",
    "            #Load images\n",
    "            x = load_dataset(source_path, batch_files)\n",
    "\n",
    "            #Normalize\n",
    "            x = np.array(x/255)\n",
    "\n",
    "            y = [class_name_map[label_dict[image]] for image in batch_files]\n",
    "            y = to_categorical(y, num_classes = num_classes)\n",
    "\n",
    "           # loaded += len(batch_files)\n",
    "           # progress_bar.set_description(\"Loaded {loaded}\".format(loaded = loaded))\n",
    "           # progress_bar.update(len(batch_files))\n",
    "\n",
    "            yield [x], y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"0000e88ab.jpg\", \"000a6daec.jpg\"]\n",
    "batch_size = 2\n",
    "for x, y in load_model_data(TRAIN_SET_LOC, files, batch_size, CLASS_NAME_MAP, LABEL_DICT, NUM_CLASSES):\n",
    "    print(x[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create label and class mapping for training set. ###\n",
    "\n",
    "#Load labels\n",
    "LABEL_DICT = {}\n",
    "\n",
    "with open(LABEL_FILE_LOC, 'r') as handle:\n",
    "    label_reader = csv.reader(handle)\n",
    "    next(label_reader, None)\n",
    "    \n",
    "    loaded_items = 0\n",
    "    for row in label_reader:\n",
    "        LABEL_DICT[row[0]] = row[1]\n",
    "    \n",
    "#Classes\n",
    "CLASS_NAMES = list(set(LABEL_DICT.values()))\n",
    "CLASS_NAME_MAP = {}\n",
    "\n",
    "class_idx = 0\n",
    "for class_name in CLASS_NAMES:\n",
    "    CLASS_NAME_MAP[class_name] = class_idx\n",
    "    class_idx += 1\n",
    "\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "print(\"Number of classses: {count}\".format(count = NUM_CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Preprocess train dataset ###\n",
    "files = list(LABEL_DICT.keys())\n",
    "\n",
    "with tqdm(total = len(files), file=stdout) as progress_bar:\n",
    "    preprocess_raw_dataset(RAW_TRAIN_SET_LOC, files, TRAIN_SET_LOC, IMG_SIZE, 256, progress_bar = progress_bar)\n",
    "\n",
    "\"\"\"\n",
    "train_raw_files = [\"0000e88ab.jpg\"]\n",
    "image = imread(locate_img(RAW_TRAIN_SET_LOC, \"0000e88ab.jpg\"))\n",
    "resized = load_dataset(RAW_TRAIN_SET_LOC, train_raw_files)\n",
    "print(resized[0])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_img(source_path, label_dict, num_files = 10):\n",
    "    files = list(label_dict.keys())[:num_files]\n",
    "\n",
    "    x = load_dataset(source_path, files)\n",
    "    x = to_grayscale(x)\n",
    "\n",
    "    y = [CLASS_NAME_MAP[LABEL_DICT[image]] for image in files]\n",
    "    y = to_categorical(y, num_classes = NUM_CLASSES)\n",
    "\n",
    "    #Print sample\n",
    "    plt.figure()\n",
    "\n",
    "    print(x[3])\n",
    "    plt.imshow(x[0], cmap='gray')\n",
    "    #plt.imshow(cvtColor((x[4]).astype('uint8'), COLOR_BGR2RGB)) #SAMPLE_IMG_ID\n",
    "\n",
    "    print(y[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(LABEL_DICT.keys())[:10]\n",
    "\n",
    "x = load_dataset(TRAIN_SET_LOC, files)\n",
    "x = to_grayscale(x)\n",
    "\n",
    "y = [CLASS_NAME_MAP[LABEL_DICT[image]] for image in files]\n",
    "y = to_categorical(y, num_classes = NUM_CLASSES)\n",
    "\n",
    "#Print sample\n",
    "plt.figure()\n",
    "\n",
    "print(x[3])\n",
    "plt.imshow(x[0], cmap='gray')\n",
    "#plt.imshow(cvtColor((x[4]).astype('uint8'), COLOR_BGR2RGB)) #SAMPLE_IMG_ID\n",
    "\n",
    "print(y[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Create the model for gray-scale inputs ###\n",
    "model = Sequential()\n",
    "\n",
    "input_shape = IMG_SIZE\n",
    "\n",
    "model.add(Conv1D(32, kernel_size = 3, activation='relu', input_shape=input_shape))\n",
    "model.add(Conv1D(32, kernel_size = 3, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv1D(64, kernel_size = 3, activation='relu'))\n",
    "model.add(Conv1D(64, kernel_size = 3, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "#Compile the model\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Print model summary\n",
    "#print(model.summary())\n",
    "\n",
    "#Training and validation sets\n",
    "files = list(LABEL_DICT.keys())[:2048]\n",
    "num_files = len(files)\n",
    "batch_size = 128\n",
    "validation_split = 0.2\n",
    "split_marker = int(num_files*(1 - validation_split))\n",
    "train_set = files[:split_marker]\n",
    "validation_set = files[split_marker:]\n",
    "\n",
    "#Train the model\n",
    "model.fit_generator(\n",
    "    load_model_data(TRAIN_SET_LOC, train_set, batch_size, CLASS_NAME_MAP, LABEL_DICT, NUM_CLASSES),\n",
    "    steps_per_epoch = (len(train_set) + batch_size - 1)/batch_size,\n",
    "    epochs = 20,\n",
    "    validation_data=load_model_data(TRAIN_SET_LOC, validation_set, batch_size, CLASS_NAME_MAP, LABEL_DICT, NUM_CLASSES),\n",
    "    validation_steps=(len(validation_set) + batch_size - 1)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the model ###\n",
    "model = Sequential()\n",
    "\n",
    "input_shape = IMG_SIZE\n",
    "\n",
    "model.add(MaxPool2D((5, 5), (2, 2), 'valid', input_shape=input_shape))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPool2D((5, 5), (2, 2), 'valid'))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool2D((5, 5), (2, 2), 'valid'))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool2D((5, 5), (2, 2), 'valid'))\n",
    "\n",
    "model.add(Conv2D(8, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool2D((5, 5), (2, 2), 'valid'))\n",
    "\n",
    "model.add(Conv2D(4, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool2D((5, 5), (2, 2), 'valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(NUM_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Print model summary\n",
    "print(model.summary())\n",
    "\n",
    "#Train the model\n",
    "files = list(LABEL_DICT.keys())[:5096]\n",
    "batch_size = 16\n",
    "model.fit_generator(\n",
    "    load_model_data(TRAIN_SET_LOC, files, 16, CLASS_NAME_MAP, LABEL_DICT, NUM_CLASSES),\n",
    "    epochs = 20, \n",
    "    steps_per_epoch = len(files)/batch_size + 1, \n",
    "    use_multiprocessing = True)\n",
    "\"\"\"\n",
    "for files in batch(list(LABEL_DICT.keys()), 256):\n",
    "    x, y = load_image_set(TRAIN_SET_LOC, files, CLASS_NAME_MAP, LABEL_DICT, NUM_CLASSES)\n",
    "    model.fit(x, y, batch_size = 16, validation_split = 0.2, epochs=3)\n",
    "\"\"\"\n",
    "\n",
    "#VG(model_to_dot(model).create(prog='dot', format='s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scratch\n",
    "#img = imread(locate_train_img(\"0000e88ab.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_TRAIN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
