{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_13 (Conv1D)           (None, 398, 32)           67232     \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 396, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 198, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 198, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 196, 64)           6208      \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 194, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 97, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 97, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 6208)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               1589504   \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5005)              1286285   \n",
      "=================================================================\n",
      "Total params: 2,964,685\n",
      "Trainable params: 2,964,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "16\n",
      "4\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.4382 - acc: 0.0000e+00 - val_loss: 8.3367 - val_acc: 0.5000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 8.3000 - acc: 0.1250 - val_loss: 7.9535 - val_acc: 0.5000\n",
      "Saving model\n"
     ]
    }
   ],
   "source": [
    "#Basic imports\n",
    "from sys import argv, stdout\n",
    "\n",
    "#Local imports\n",
    "from common import constants\n",
    "from models import model_1\n",
    "from model_utils import get_image_labels, get_label_ids, model_fit_data_feeder\n",
    "from utils import list_files\n",
    "\n",
    "batch_size = 16\n",
    "n_images = 20\n",
    "n_epochs = 2\n",
    "model_name = \"model_1\"\n",
    "\n",
    "dataset = \"train\"\n",
    "validation_split = 0.2\n",
    "input_shape = constants.IMG_SHAPE\n",
    "source_loc = constants.PROCESSED_DATASET_MAPPINGS[dataset]\n",
    "\n",
    "image_labels = get_image_labels()\n",
    "label_ids = get_label_ids()\n",
    "num_classes = len(label_ids)\n",
    "img_files = list_files(source_loc, n_images)\n",
    "n_images = len(img_files)\n",
    "\n",
    "#Training and validation sets\n",
    "split_marker = int(n_images*(1 - validation_split))\n",
    "train_set = img_files[:split_marker]\n",
    "validation_set = img_files[split_marker:]\n",
    "\n",
    "#Initialize the model\n",
    "model = model_1(input_shape, num_classes)\n",
    "model.summary()\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(validation_set))\n",
    "\n",
    "#Train the model\n",
    "model.fit_generator(\n",
    "    model_fit_data_feeder(\"training\", source_loc, train_set, batch_size, image_labels, label_ids),\n",
    "    steps_per_epoch = int((len(train_set) + batch_size - 1)/batch_size),\n",
    "    epochs = n_epochs,\n",
    "    validation_data=model_fit_data_feeder(\"validation\", source_loc, validation_set, batch_size, image_labels, label_ids),\n",
    "    validation_steps=int((len(validation_set) + batch_size - 1)/batch_size))\n",
    "\n",
    "#Save model\n",
    "print(\"Saving model\")\n",
    "model.save('model.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_data(source_path, files, batch_size, class_name_map, label_dict, num_classes):\n",
    "    #Image batch placeholder\n",
    "    x = None\n",
    "    \n",
    "    #Labels placeholder\n",
    "    y = None\n",
    "\n",
    "   # with tqdm(total = len(files), file=stdout) as progress_bar:\n",
    "    #    loaded = 0\n",
    "    while True:\n",
    "        shuffle(files)\n",
    "        for batch_files in batch(files, batch_size):\n",
    "            #Load images\n",
    "            x = load_dataset(source_path, batch_files)\n",
    "\n",
    "            #Normalize\n",
    "            x = np.array(x/255)\n",
    "\n",
    "            y = [class_name_map[label_dict[image]] for image in batch_files]\n",
    "            y = to_categorical(y, num_classes = num_classes)\n",
    "\n",
    "           # loaded += len(batch_files)\n",
    "           # progress_bar.set_description(\"Loaded {loaded}\".format(loaded = loaded))\n",
    "           # progress_bar.update(len(batch_files))\n",
    "\n",
    "            yield [x], y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"0000e88ab.jpg\", \"000a6daec.jpg\"]\n",
    "batch_size = 2\n",
    "for x, y in load_model_data(TRAIN_SET_LOC, files, batch_size, CLASS_NAME_MAP, LABEL_DICT, NUM_CLASSES):\n",
    "    print(x[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create label and class mapping for training set. ###\n",
    "\n",
    "#Load labels\n",
    "LABEL_DICT = {}\n",
    "\n",
    "with open(LABEL_FILE_LOC, 'r') as handle:\n",
    "    label_reader = csv.reader(handle)\n",
    "    next(label_reader, None)\n",
    "    \n",
    "    loaded_items = 0\n",
    "    for row in label_reader:\n",
    "        LABEL_DICT[row[0]] = row[1]\n",
    "    \n",
    "#Classes\n",
    "CLASS_NAMES = list(set(LABEL_DICT.values()))\n",
    "CLASS_NAME_MAP = {}\n",
    "\n",
    "class_idx = 0\n",
    "for class_name in CLASS_NAMES:\n",
    "    CLASS_NAME_MAP[class_name] = class_idx\n",
    "    class_idx += 1\n",
    "\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "print(\"Number of classses: {count}\".format(count = NUM_CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Preprocess train dataset ###\n",
    "files = list(LABEL_DICT.keys())\n",
    "\n",
    "with tqdm(total = len(files), file=stdout) as progress_bar:\n",
    "    preprocess_raw_dataset(RAW_TRAIN_SET_LOC, files, TRAIN_SET_LOC, IMG_SIZE, 256, progress_bar = progress_bar)\n",
    "\n",
    "\"\"\"\n",
    "train_raw_files = [\"0000e88ab.jpg\"]\n",
    "image = imread(locate_img(RAW_TRAIN_SET_LOC, \"0000e88ab.jpg\"))\n",
    "resized = load_dataset(RAW_TRAIN_SET_LOC, train_raw_files)\n",
    "print(resized[0])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_img(source_path, label_dict, num_files = 10):\n",
    "    files = list(label_dict.keys())[:num_files]\n",
    "\n",
    "    x = load_dataset(source_path, files)\n",
    "    x = to_grayscale(x)\n",
    "\n",
    "    y = [CLASS_NAME_MAP[LABEL_DICT[image]] for image in files]\n",
    "    y = to_categorical(y, num_classes = NUM_CLASSES)\n",
    "\n",
    "    #Print sample\n",
    "    plt.figure()\n",
    "\n",
    "    print(x[3])\n",
    "    plt.imshow(x[0], cmap='gray')\n",
    "    #plt.imshow(cvtColor((x[4]).astype('uint8'), COLOR_BGR2RGB)) #SAMPLE_IMG_ID\n",
    "\n",
    "    print(y[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(LABEL_DICT.keys())[:10]\n",
    "\n",
    "x = load_dataset(TRAIN_SET_LOC, files)\n",
    "x = to_grayscale(x)\n",
    "\n",
    "y = [CLASS_NAME_MAP[LABEL_DICT[image]] for image in files]\n",
    "y = to_categorical(y, num_classes = NUM_CLASSES)\n",
    "\n",
    "#Print sample\n",
    "plt.figure()\n",
    "\n",
    "print(x[3])\n",
    "plt.imshow(x[0], cmap='gray')\n",
    "#plt.imshow(cvtColor((x[4]).astype('uint8'), COLOR_BGR2RGB)) #SAMPLE_IMG_ID\n",
    "\n",
    "print(y[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Create the model for gray-scale inputs ###\n",
    "model = Sequential()\n",
    "\n",
    "input_shape = IMG_SIZE\n",
    "\n",
    "model.add(Conv1D(32, kernel_size = 3, activation='relu', input_shape=input_shape))\n",
    "model.add(Conv1D(32, kernel_size = 3, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv1D(64, kernel_size = 3, activation='relu'))\n",
    "model.add(Conv1D(64, kernel_size = 3, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "#Compile the model\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Print model summary\n",
    "#print(model.summary())\n",
    "\n",
    "#Training and validation sets\n",
    "files = list(LABEL_DICT.keys())[:2048]\n",
    "num_files = len(files)\n",
    "batch_size = 128\n",
    "validation_split = 0.2\n",
    "split_marker = int(num_files*(1 - validation_split))\n",
    "train_set = files[:split_marker]\n",
    "validation_set = files[split_marker:]\n",
    "\n",
    "#Train the model\n",
    "model.fit_generator(\n",
    "    load_model_data(TRAIN_SET_LOC, train_set, batch_size, CLASS_NAME_MAP, LABEL_DICT, NUM_CLASSES),\n",
    "    steps_per_epoch = (len(train_set) + batch_size - 1)/batch_size,\n",
    "    epochs = 20,\n",
    "    validation_data=load_model_data(TRAIN_SET_LOC, validation_set, batch_size, CLASS_NAME_MAP, LABEL_DICT, NUM_CLASSES),\n",
    "    validation_steps=(len(validation_set) + batch_size - 1)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the model ###\n",
    "model = Sequential()\n",
    "\n",
    "input_shape = IMG_SIZE\n",
    "\n",
    "model.add(MaxPool2D((5, 5), (2, 2), 'valid', input_shape=input_shape))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPool2D((5, 5), (2, 2), 'valid'))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool2D((5, 5), (2, 2), 'valid'))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool2D((5, 5), (2, 2), 'valid'))\n",
    "\n",
    "model.add(Conv2D(8, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool2D((5, 5), (2, 2), 'valid'))\n",
    "\n",
    "model.add(Conv2D(4, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool2D((5, 5), (2, 2), 'valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(NUM_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Print model summary\n",
    "print(model.summary())\n",
    "\n",
    "#Train the model\n",
    "files = list(LABEL_DICT.keys())[:5096]\n",
    "batch_size = 16\n",
    "model.fit_generator(\n",
    "    load_model_data(TRAIN_SET_LOC, files, 16, CLASS_NAME_MAP, LABEL_DICT, NUM_CLASSES),\n",
    "    epochs = 20, \n",
    "    steps_per_epoch = len(files)/batch_size + 1, \n",
    "    use_multiprocessing = True)\n",
    "\"\"\"\n",
    "for files in batch(list(LABEL_DICT.keys()), 256):\n",
    "    x, y = load_image_set(TRAIN_SET_LOC, files, CLASS_NAME_MAP, LABEL_DICT, NUM_CLASSES)\n",
    "    model.fit(x, y, batch_size = 16, validation_split = 0.2, epochs=3)\n",
    "\"\"\"\n",
    "\n",
    "#VG(model_to_dot(model).create(prog='dot', format='s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scratch\n",
    "#img = imread(locate_train_img(\"0000e88ab.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_TRAIN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
